<!DOCTYPE html>
<html>
<head>
    

    

    



    <meta charset="utf-8">
    
    
    
    <title>CS231n学习笔记 Module 1.1 | E.I. | Are you too proud to kiss me?</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    
    <meta name="theme-color" content="#81D8CF">
    
    
    <meta name="keywords" content="笔记,CNN">
    <meta name="description" content="Abstract Assignment Git:https://github.com/CS231n-zju/CS231n 视频地址：https://www.youtube.com/watch?v=vT1JzLTH4G4&amp;amp;index=2&amp;amp;list=PLe7764SJVnV10-Nr7e0sBlC9J0LRf4sQo 课程作业：http://cs231n.github.io/ Syll">
<meta name="keywords" content="笔记,CNN">
<meta property="og:type" content="article">
<meta property="og:title" content="CS231n学习笔记 Module 1.1">
<meta property="og:url" content="http://wenbo.fun/2018/04/11/cs231n_m1_1/index.html">
<meta property="og:site_name" content="E.I.">
<meta property="og:description" content="Abstract Assignment Git:https://github.com/CS231n-zju/CS231n 视频地址：https://www.youtube.com/watch?v=vT1JzLTH4G4&amp;amp;index=2&amp;amp;list=PLe7764SJVnV10-Nr7e0sBlC9J0LRf4sQo 课程作业：http://cs231n.github.io/ Syll">
<meta property="og:locale" content="zh-cn">
<meta property="og:image" content="http://cs231n.github.io/assets/pixelspace.jpeg">
<meta property="og:image" content="http://cs231n.github.io/assets/wb.jpeg">
<meta property="og:image" content="http://cs231n.github.io/assets/svmvssoftmax.png">
<meta property="og:updated_time" content="2018-05-23T02:29:39.396Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="CS231n学习笔记 Module 1.1">
<meta name="twitter:description" content="Abstract Assignment Git:https://github.com/CS231n-zju/CS231n 视频地址：https://www.youtube.com/watch?v=vT1JzLTH4G4&amp;amp;index=2&amp;amp;list=PLe7764SJVnV10-Nr7e0sBlC9J0LRf4sQo 课程作业：http://cs231n.github.io/ Syll">
<meta name="twitter:image" content="http://cs231n.github.io/assets/pixelspace.jpeg">
    
        <link rel="alternate" type="application/atom+xml" title="E.I." href="/atom.xml">
    
    <link rel="shortcut icon" href="/favicon.ico">

    <!--  <link rel="stylesheet" href="/css/style.css?v=1.7.1"> -->
    <link rel="stylesheet" href="/css/style.css">
    <script>window.lazyScripts=[]</script>

    <!-- custom head -->
    

</head>

<body>
    <div id="loading" class="active"></div>

    <aside id="menu" class="hide" >
  <div class="inner flex-row-vertical">
    <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="menu-off">
        <i class="icon icon-lg icon-close"></i>
    </a>
    <div class="brand-wrap" style="background-image:url(http://7xsg2l.com1.z0.glb.clouddn.com/blog/imgbrand.jpg)">
      <div class="brand">
        <a href="/" class="avatar waves-effect waves-circle waves-light">
          <img src="http://7xsg2l.com1.z0.glb.clouddn.com/blog/img/cc.jpeg">
        </a>
        <hgroup class="introduce">
          <h5 class="nickname">Wen bo</h5>
          <a href="mailto:1871756080@qq.com" title="1871756080@qq.com" class="mail">1871756080@qq.com</a>
        </hgroup>
      </div>
    </div>
    <div class="scroll-wrap flex-col">
      <ul class="nav">
        
            <li class="waves-block waves-effect">
              <a href="/"  >
                <i class="icon icon-lg icon-home"></i>
                Home
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/archives"  >
                <i class="icon icon-lg icon-archives"></i>
                Archives
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/tags"  >
                <i class="icon icon-lg icon-tags"></i>
                Tags
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/categories"  >
                <i class="icon icon-lg icon-th-list"></i>
                Categories
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="https://github.com/wenbo8585" target="_blank" >
                <i class="icon icon-lg icon-github"></i>
                Github
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/MVision"  >
                <i class="icon icon-lg icon-link"></i>
                CoCo
              </a>
            </li>
        
      </ul>
    </div>
  </div>
</aside>

    <main id="main">
        <header class="top-header" id="header">
    <div class="flex-row">
        <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light on" id="menu-toggle">
          <i class="icon icon-lg icon-navicon"></i>
        </a>
        <div class="flex-col header-title ellipsis">CS231n学习笔记 Module 1.1</div>
        
        <div class="search-wrap" id="search-wrap">
            <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="back">
                <i class="icon icon-lg icon-chevron-left"></i>
            </a>
            <input type="text" id="key" class="search-input" autocomplete="off" placeholder="Search">
            <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="search">
                <i class="icon icon-lg icon-search"></i>
            </a>
        </div>
        
        
        <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="menuShare">
            <i class="icon icon-lg icon-share-alt"></i>
        </a>
        
    </div>
</header>
<header class="content-header post-header">

    <div class="container fade-scale">
        <h1 class="title">CS231n学习笔记 Module 1.1</h1>
        <h5 class="subtitle">
            
                <time datetime="2018-04-11T09:15:17.000Z" itemprop="datePublished" class="page-time">
  2018-04-11
</time>


	<ul class="article-category-list"><li class="article-category-list-item"><a class="article-category-list-link" href="/categories/笔记/">笔记</a></li></ul>

            
        </h5>
    </div>

    


</header>


<div class="container body-wrap">
    
    <aside class="post-widget">
        <nav class="post-toc-wrap" id="post-toc">
            <h4>TOC</h4>
            <ol class="post-toc"><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#Abstract"><span class="post-toc-number">1.</span> <span class="post-toc-text">Abstract</span></a></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#Lecture-1"><span class="post-toc-number">2.</span> <span class="post-toc-text">Lecture 1</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#Image-Classification"><span class="post-toc-number">2.1.</span> <span class="post-toc-text">Image Classification</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#The-image-classification-pipeline"><span class="post-toc-number">2.1.1.</span> <span class="post-toc-text">The image classification pipeline</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Nearest-Neighbor-Classifier"><span class="post-toc-number">2.1.2.</span> <span class="post-toc-text">Nearest Neighbor Classifier</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#k-Nearest-Neighbor-Classifier"><span class="post-toc-number">2.1.3.</span> <span class="post-toc-text">k - Nearest Neighbor Classifier</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Validation-sets-for-Hyperparameter-tuning-用于超参数调优的验证集"><span class="post-toc-number">2.1.4.</span> <span class="post-toc-text">Validation sets for Hyperparameter tuning (用于超参数调优的验证集)</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#N-fold-cross-validation"><span class="post-toc-number">2.1.5.</span> <span class="post-toc-text">N-fold cross-validation</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Pros-and-Cons-of-Nearest-Neighbor-classifier"><span class="post-toc-number">2.1.6.</span> <span class="post-toc-text">Pros and Cons of Nearest Neighbor classifier</span></a></li></ol></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#Linear-Classification"><span class="post-toc-number">2.2.</span> <span class="post-toc-text">Linear Classification</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Parameterized-mapping-from-images-to-label-scores"><span class="post-toc-number">2.2.1.</span> <span class="post-toc-text">Parameterized mapping from images to label scores</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Interpreting-a-linear-classifier"><span class="post-toc-number">2.2.2.</span> <span class="post-toc-text">Interpreting a linear classifier</span></a></li></ol></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#Loss-function"><span class="post-toc-number">2.3.</span> <span class="post-toc-text">Loss function</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Multiclass-Support-Vector-Machine-loss"><span class="post-toc-number">2.3.1.</span> <span class="post-toc-text">Multiclass Support Vector Machine loss</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Softmax-classifier"><span class="post-toc-number">2.3.2.</span> <span class="post-toc-text">Softmax classifier</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#SVM-vs-Softmax"><span class="post-toc-number">2.3.3.</span> <span class="post-toc-text">SVM vs. Softmax</span></a></li></ol></li></ol></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#Unknown-words"><span class="post-toc-number">3.</span> <span class="post-toc-text">Unknown words</span></a></li></ol>
        </nav>
    </aside>
    
<article id="post-cs231n_m1_1"
  class="post-article article-type-post fade" itemprop="blogPost">

    <div class="post-card">
        <h1 class="post-card-title">CS231n学习笔记 Module 1.1</h1>
        <div class="post-meta">
            <time class="post-time" title="2018-04-11 17:15:17" datetime="2018-04-11T09:15:17.000Z"  itemprop="datePublished">2018-04-11</time>

            
	<ul class="article-category-list"><li class="article-category-list-item"><a class="article-category-list-link" href="/categories/笔记/">笔记</a></li></ul>



            
<span id="busuanzi_container_page_pv" title="文章总阅读量" style='display:none'>
    <i class="icon icon-eye icon-pr"></i><span id="busuanzi_value_page_pv"></span>
</span>


        </div>
        <div class="post-content" id="post-content" itemprop="postContent">
            <h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><blockquote>
<p>Assignment Git:<br><a href="https://github.com/CS231n-zju/CS231n" target="_blank" rel="noopener">https://github.com/CS231n-zju/CS231n</a></p>
<p>视频地址：<br><a href="https://www.youtube.com/watch?v=vT1JzLTH4G4&amp;index=2&amp;list=PLe7764SJVnV10-Nr7e0sBlC9J0LRf4sQo" target="_blank" rel="noopener">https://www.youtube.com/watch?v=vT1JzLTH4G4&amp;index=2&amp;list=PLe7764SJVnV10-Nr7e0sBlC9J0LRf4sQo</a></p>
<p>课程作业：<br><a href="http://cs231n.github.io/" target="_blank" rel="noopener">http://cs231n.github.io/</a></p>
<p>Syllabus:<br><a href="http://cs231n.stanford.edu/syllabus.html" target="_blank" rel="noopener">http://cs231n.stanford.edu/syllabus.html</a></p>
<p>Note翻译:<br><a href="http://www.52ml.net/17723.html" target="_blank" rel="noopener">http://www.52ml.net/17723.html</a></p>
</blockquote>
<h1 id="Lecture-1"><a href="#Lecture-1" class="headerlink" title="Lecture 1"></a>Lecture 1</h1><p><strong>Introduction to Convolutional Neural Networks for Visual Recognition</strong></p>
<p><strong>NOTE</strong></p>
<ul>
<li>2012 CNN ImageNet</li>
</ul>
<a id="more"></a>
<h2 id="Image-Classification"><a href="#Image-Classification" class="headerlink" title="Image Classification"></a>Image Classification</h2><p><strong>Challenges</strong></p>
<ul>
<li>Viewpoint variation</li>
<li>Scale variation</li>
<li>Deformation</li>
<li>Occlusion</li>
<li>Illumination conditions</li>
<li>Background clutter</li>
<li>Intra-class variation： The classes of interest can often be relatively broad, such as chair. There are many different types of these objects, each with their own appearance.(一类物体的个体之间的外形差异很大，比如椅子。这一类物体有许多不同的对象，每个都有自己的外形。)</li>
</ul>
<h3 id="The-image-classification-pipeline"><a href="#The-image-classification-pipeline" class="headerlink" title="The image classification pipeline"></a>The image classification pipeline</h3><ul>
<li>Input: training set.</li>
<li>Learning: training a classifier, or learning a model.</li>
<li>Evaluation: In the end, we evaluate the quality of the classifier by asking it to predict labels for a new set of images that it has never seen before.</li>
</ul>
<h3 id="Nearest-Neighbor-Classifier"><a href="#Nearest-Neighbor-Classifier" class="headerlink" title="Nearest Neighbor Classifier"></a>Nearest Neighbor Classifier</h3><p>How we compare two images?</p>
<p> <strong>L1 distance</strong>: $$d(I_1,I_2)=\sum|I_1^p - I_2^p|$$</p>
<p>As an evaluation criterion, it is common to use the <strong>accuracy</strong>.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">NearestNeighbor</span><span class="params">(object)</span>:</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(self, X, y)</span>:</span></span><br><span class="line">    <span class="string">""" X is N x D where each row is an example. Y is 1-dimension of size N """</span></span><br><span class="line">    <span class="comment"># the nearest neighbor classifier simply remembers all the training data</span></span><br><span class="line">    self.Xtr = X</span><br><span class="line">    self.ytr = y</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(self, X)</span>:</span></span><br><span class="line">    <span class="string">""" X is N x D where each row is an example we wish to predict label for """</span></span><br><span class="line">    num_test = X.shape[<span class="number">0</span>]</span><br><span class="line">    <span class="comment"># lets make sure that the output type matches the input type</span></span><br><span class="line">    Ypred = np.zeros(num_test, dtype = self.ytr.dtype)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># loop over all test rows</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> xrange(num_test):</span><br><span class="line">      <span class="comment"># find the nearest training image to the i'th test image</span></span><br><span class="line">      <span class="comment"># using the L1 distance (sum of absolute value differences)</span></span><br><span class="line">      distances = np.sum(np.abs(self.Xtr - X[i,:]), axis = <span class="number">1</span>)</span><br><span class="line">      min_index = np.argmin(distances) <span class="comment"># get the index with smallest distance</span></span><br><span class="line">      Ypred[i] = self.ytr[min_index] <span class="comment"># predict the label of the nearest example</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> Ypred</span><br></pre></td></tr></table></figure>
<p><strong>L2 distance(欧氏距离)</strong>: $$d(I_1,I_2)=\sqrt{\sum_p{|I_1^p - I_2^p|}^2}$$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">distances = np.sqrt(np.sum(np.square(self.Xtr - X[i,:]), axis = <span class="number">1</span>))</span><br></pre></td></tr></table></figure>
<p>the L2 distance is much more unforgiving than the L1 distance.</p>
<h3 id="k-Nearest-Neighbor-Classifier"><a href="#k-Nearest-Neighbor-Classifier" class="headerlink" title="k - Nearest Neighbor Classifier"></a>k - Nearest Neighbor Classifier</h3><p>找最相似的k个图片的标签，然后让他们针对测试图片进行投票，最后把票数最高的标签作为对测试图片的预测。k的值？</p>
<h3 id="Validation-sets-for-Hyperparameter-tuning-用于超参数调优的验证集"><a href="#Validation-sets-for-Hyperparameter-tuning-用于超参数调优的验证集" class="headerlink" title="Validation sets for Hyperparameter tuning (用于超参数调优的验证集)"></a>Validation sets for Hyperparameter tuning (用于超参数调优的验证集)</h3><ul>
<li><p>we cannot use the test set for the purpose of tweaking hyperparameters,   <strong>overfit</strong>.</p>
</li>
<li><p>Evaluate on the test set only a single time, at the very end.</p>
</li>
<li><p>to split our training set in two: a slightly smaller training set, and what we call a <strong>validation set</strong>.</p>
</li>
</ul>
<p>这里将5万张train中1千张作为验证集，来寻找最优的k。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># assume we have Xtr_rows, Ytr, Xte_rows, Yte as before</span></span><br><span class="line"><span class="comment"># recall Xtr_rows is 50,000 x 3072 matrix</span></span><br><span class="line">Xval_rows = Xtr_rows[:<span class="number">1000</span>, :] <span class="comment"># take first 1000 for validation</span></span><br><span class="line">Yval = Ytr[:<span class="number">1000</span>]</span><br><span class="line">Xtr_rows = Xtr_rows[<span class="number">1000</span>:, :] <span class="comment"># keep last 49,000 for train</span></span><br><span class="line">Ytr = Ytr[<span class="number">1000</span>:]</span><br><span class="line"></span><br><span class="line"><span class="comment"># find hyperparameters that work best on the validation set</span></span><br><span class="line">validation_accuracies = []</span><br><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> [<span class="number">1</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">10</span>, <span class="number">20</span>, <span class="number">50</span>, <span class="number">100</span>]:</span><br><span class="line"></span><br><span class="line"><span class="comment"># use a particular value of k and evaluation on validation data</span></span><br><span class="line">  nn = NearestNeighbor()</span><br><span class="line">  nn.train(Xtr_rows, Ytr)</span><br><span class="line">  <span class="comment"># here we assume a modified NearestNeighbor class that can take a k as input</span></span><br><span class="line">  Yval_predict = nn.predict(Xval_rows, k = k)</span><br><span class="line">  acc = np.mean(Yval_predict == Yval)</span><br><span class="line">  <span class="keyword">print</span> <span class="string">'accuracy: %f'</span> % (acc,)</span><br><span class="line"><span class="comment"># keep track of what works on the validation set</span></span><br><span class="line">  validation_accuracies.append((k, acc))</span><br></pre></td></tr></table></figure>
<h3 id="N-fold-cross-validation"><a href="#N-fold-cross-validation" class="headerlink" title="N-fold cross-validation"></a>N-fold cross-validation</h3><p>5份交叉验证对k值调优的例子。将训练集平均分成5份，循环着取其中4份来训练，份来验证针,对每个k值，得到5个准确率结果，取其平均值。</p>
<h3 id="Pros-and-Cons-of-Nearest-Neighbor-classifier"><a href="#Pros-and-Cons-of-Nearest-Neighbor-classifier" class="headerlink" title="Pros and Cons of Nearest Neighbor classifier"></a>Pros and Cons of Nearest Neighbor classifier</h3><ul>
<li>Approximate Nearest Neighbor (ANN) algorithms and libraries exist that can accelerate the nearest neighbor lookup in a dataset (e.g. FLANN)</li>
<li>低维适用(图片一般高维，高维度向量之间的距离通常是反直觉的)</li>
</ul>
<p>实际应用K-NN:</p>
<ul>
<li>Preprocess your data：对你数据中的特征进行归一化(normalize)</li>
<li>Dimensionality reduction technique, such as PCA</li>
<li>…</li>
</ul>
<hr>
<h2 id="Linear-Classification"><a href="#Linear-Classification" class="headerlink" title="Linear Classification"></a>Linear Classification</h2><p>kNN , disadvantages:</p>
<ul>
<li><p>The classifier must remember all of the training data and store it for future comparisons with test data.  space inefficient</p>
</li>
<li><p>Classifying a test image is expensive</p>
</li>
</ul>
<h3 id="Parameterized-mapping-from-images-to-label-scores"><a href="#Parameterized-mapping-from-images-to-label-scores" class="headerlink" title="Parameterized mapping from images to label scores"></a>Parameterized mapping from images to label scores</h3><p>CIFAR-10: <strong>N</strong> = 50,000 images, <strong>D</strong> = 32 x 32 x 3 pixels, <strong>K</strong> = 10 classess.  </p>
<p>score function: $f:R^D\mapsto R^K$</p>
<p><strong>Linear classifier</strong></p>
<p>A linear mapping: $f(x_i,W,b) = Wx_i + b$</p>
<p>$x_i$: 输入图像,flattened out to a single column vector of shape [D x 1].<br>Matrix $W$(weight) of size [K x D], the vector $b$(bias vector) of size [K x 1].</p>
<p>NOTE:</p>
<ul>
<li>each Classifier is a row of $W$</li>
</ul>
<h3 id="Interpreting-a-linear-classifier"><a href="#Interpreting-a-linear-classifier" class="headerlink" title="Interpreting a linear classifier"></a>Interpreting a linear classifier</h3><p><strong>Analogy of images as high-dimensional points</strong> 将图像看作高维空间的点</p>
<p>Since the images are stretched into high-dimensional column vectors, we can interpret each image as a single point in this space</p>
<p>we defined the score of each class as a weighted sum of all image pixels, each class score is a linear function over this space.</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="http://cs231n.github.io/assets/pixelspace.jpeg" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>$W$ 的每一行都是一个分类类别的分类器。</p>
<p>Change one of the rows of $W$, the corresponding line in the pixel space will rotate in different directions.<br>如果改变其中一行的数字，会看见分类器在空间中对应的直线开始向着不同方向旋转。</p>
<p>而偏差$b$，则允许分类器对应的translate the lines直线平移。如果没有偏差，所有分类器的线都不得不穿过原点。</p>
<p><strong>Interpretation of linear classifiers as template matching</strong></p>
<p>Another interpretation for the weights $W$:</p>
<p>each row of $W$ corresponds to a template (or sometimes also called a prototype) for one of the classes.</p>
<ul>
<li>using an inner product (or dot product) one by one to find the one that <code>fits</code> best.</li>
</ul>
<p>可以认为还是在高效地使用 k-NN，不同的是我们没有使用所有的训练集的图像来比较，而是每个类别只用了一张图片（这张图片是我们学习到的，而不是训练集中的某一张），而且我们会使用（负）内积来计算向量间的距离，而不是使用L1或者L2距离。</p>
<p><strong>Bias trick</strong></p>
<p>合并 W 和 b，在 $x_i$ 末尾加 1</p>
<p>$$f(x_i,W,b) = Wx_i + b  \longrightarrow f(x_i,W) = Wx_i$$  </p>
<p><img src="http://cs231n.github.io/assets/wb.jpeg" alt=""></p>
<p><strong>image data preprocessing</strong></p>
<p>normalization</p>
<p>range from [-1,1],zero mean centering</p>
<hr>
<h2 id="Loss-function"><a href="#Loss-function" class="headerlink" title="Loss function"></a>Loss function</h2><p>sometimes also referred to as <strong>cos function</strong> or the <strong>objective</strong>(目标函数)</p>
<h3 id="Multiclass-Support-Vector-Machine-loss"><a href="#Multiclass-Support-Vector-Machine-loss" class="headerlink" title="Multiclass Support Vector Machine loss"></a>Multiclass Support Vector Machine loss</h3><p>The Multiclass SVM loss for the i-th example is then formalized as follows:<br>$$L_i = \sum_{j\neq y_i} max(0, s_j - s_{y_i} + \Delta)$$</p>
<p><strong>Example</strong>:</p>
<p>a scores $s=[13,-7,11]$ and that the first class is the true, assume that $\Delta$ is 10. The expression above sums over all incorrect classes ($ j\neq y_j$), so we get two terms:<br>$$L_i = max(0,-7-13+10) + max(0,11-13+10)$$</p>
<p><strong>hinge loss</strong>: $max(0,-)$ ,sometimes use $max(0,-)^2$将更强烈（平方地而不是线性地）地惩罚过界的边界值。</p>
<p><strong>Regularization</strong>: bug -&gt; loss 为0 ，M就可有无数个。<br>为了避免这种情况，在loss中增加 regularization penalty,常用 L2 norm 来 discourages large weights.<br>$$R(W) = \sum_k\sum_lW^2_{k,l}$$</p>
<p> the full Multiclass SVM loss becomes:<br>$$L =  \underbrace{ \frac{1}{N} \sum_i L_i }_\text{data loss} + \underbrace{ \lambda R(W) }_\text{regularization loss} $$<br> Where $N$ is the number of training examples.</p>
<ul>
<li><p>this effect can improve the generalization performance of the classifiers on test images and lead to less <em>overfitting</em></p>
<p>L2惩罚倾向于更小更分散的W权重向量。</p>
<p><strong>正则化的意义</strong></p>
</li>
</ul>
<p>不添加正则项, loss 会使 w 更拟合 training data，添加后， 更加拟合未知数据。</p>
<p>使拟合函数曲线更加趋向于低次表达， 越简单越正确。</p>
<p><strong>程序解释</strong></p>
<p>作业要求用微分分析方法（而不是数值分析法）来计算梯度，svm_loss_naive中允许使用循环</p>
<p>svm_loss_naive：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">....</span><br><span class="line">num_classes = W.shape[<span class="number">1</span>]</span><br><span class="line">  num_train = X.shape[<span class="number">0</span>]</span><br><span class="line">  loss = <span class="number">0.0</span></span><br><span class="line">  <span class="keyword">for</span> i <span class="keyword">in</span> xrange(num_train):</span><br><span class="line">    scores = X[i].dot(W)</span><br><span class="line">    correct_class_score = scores[y[i]]</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> xrange(num_classes):</span><br><span class="line">      <span class="keyword">if</span> j == y[i]:</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">      margin = scores[j] - correct_class_score + <span class="number">1</span> <span class="comment"># note delta = 1</span></span><br><span class="line">      <span class="keyword">if</span> margin &gt; <span class="number">0</span>:</span><br><span class="line">        loss += margin</span><br><span class="line">        dW[:,j] += X[i].T</span><br><span class="line">        dW[:,y[i]] += -X[i].T</span><br><span class="line">....</span><br></pre></td></tr></table></figure>
<p>其中，scores = X[i].dot(W)就是下面计算loss 中的 f 函数。<br>$$L = \frac{1}{N} \sum_i \sum_{j\neq y_i} \left[ \max(0, f(x_i; W)_j - f(x_i; W)_{y_i} + \Delta) \right] + \lambda \sum_k\sum_l W_{k,l}^2$$</p>
<p>这样得出的scores是X[i]关于权重W（含偏置）的各个分类器的得分，是一个C维向量（假设共有C个分类）。</p>
<p>最后两行：</p>
<p>在j不等于y_i的时候，求偏导就是 d scores，为 X[i].T, 最后总式子的累加符号中可以看出j不等于y_i，在j等于y_i的时候,累加中只有减号后才有y_i项，求偏导时前面都是0，减号后项保留，得到结果 -X[i].T 。</p>
<p>既然W_yi的作用是要使得损失函数 L_i最小，那么就给 W_yi 加上若干个 Xi（这里为负号，但在SGD计算时采用负梯度方向，所以实际效果为相加），使得 Wyi的权重值变大，结果是新一轮迭代时损失函数应该变小。</p>
<p>svm_loss_vectorized:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">....</span><br><span class="line">num_train = X.shape[<span class="number">0</span>]</span><br><span class="line">  num_classes = W.shape[<span class="number">1</span>]</span><br><span class="line">  scores = X.dot(W)</span><br><span class="line">  correct_class_scores = scores[range(num_train), list(y)].reshape(<span class="number">-1</span>,<span class="number">1</span>) <span class="comment">#(N, 1)</span></span><br><span class="line">  margins = np.maximum(<span class="number">0</span>, scores - correct_class_scores +<span class="number">1</span>)</span><br><span class="line">  margins[range(num_train), list(y)] = <span class="number">0</span></span><br><span class="line">  loss = np.sum(margins) / num_train + <span class="number">0.5</span> * reg * np.sum(W * W)</span><br><span class="line">....</span><br></pre></td></tr></table></figure>
<p>参照公式一目了然。</p>
<p>后面 0.5 有的说通常加入0.5是为了计算regulation loss的梯度时系数变为1。这个应该是看如何定义的。</p>
<p><strong>Setting Delta</strong></p>
<p>can safely be set to $Δ=1.0$ in all cases. 它影响的是 w 的大小而不是 loss.the only real tradeoff is how large we allow the weights to grow (through the regularization strength $λ$).</p>
<h3 id="Softmax-classifier"><a href="#Softmax-classifier" class="headerlink" title="Softmax classifier"></a>Softmax classifier</h3><p>$f(x_i,W) = Wx_i$ unchanged,interpret these scores as the unnormalized log probabilities(未归一化的对数概率) for each class and replace the <em>hinge loss</em> with a <em>cross-entropy loss</em>(交叉熵损失) that has the form:<br>$$L_i = -\log( {e^{f_{y_i}} \over \sum_je^{f_j} }) \ \ \ \ or \ \ \ L_i = -f_{y_i} + \log\sum_je^{f_j}$$</p>
<p> $f_j$ to mean the j-th element of the vector of class scores $f$.<br> $f_{y_i}$ to mean 把 i 分类为 $y_i$ 的 score. (j can = $y_j$ ? )</p>
<p> $L_i$ 控制在[0,1]</p>
<p> <strong>Information theory view</strong>: The <em>cross-entropy</em> between a “true” distribution $p$ and an estimated distribution(预测分布) $q$ is defined as:<br> $$H(p,q) = -\sum{p(x) \log q(x)}$$</p>
<p>希望真实分布于预测分布的交叉熵最小，即差异最小。</p>
<p><strong>Probabilistic interpretation</strong>:<br>To see $$P(y_i | x_i; W) = { e^{f_{y_i}} \over \sum_j e^{f_j} }$$<br>给定图像数据$x_i$，以$W$为参数，分配给正确分类标签$y_i$的 normalized probability (归一化概率)。</p>
<p><strong>Practical issues: Numeric stability</strong>:</p>
<p>存在指数函数，所以数值可能非常大。除以大数值可能导致数值计算的不稳定。Notice that if we multiply the top and bottom of the fraction by a constant $C$ (常数C) ，通常取: $ \log C = max_jf_j$</p>
<p>$$\frac{e^{f_{y_i}}}{\sum_j e^{f_j}}<br>= \frac{Ce^{f_{y_i}}}{C\sum_j e^{f_j}}<br>= \frac{e^{f_{y_i} + \log C}}{\sum_j e^{f_j + \log C}}$$</p>
<p>这样指数就 &lt;= 0,分子分母都小于1。</p>
<p><strong>名词误解</strong>: SVM分类器使用的是折叶损失（hinge loss），有时候又被称为最大边界损失（max-margin loss）。Softmax分类器使用的是交叉熵损失（corss-entropy loss）。Softmax分类器的命名是从softmax函数那里得来的，softmax函数将原始分类评分变成正的归一化数值，所有数值和为1，这样处理后交叉熵损失才能应用。注意从技术上说“softmax损失（softmax loss）”是没有意义的，因为softmax只是一个压缩数值的函数。但是在这个说法常常被用来做简称。</p>
<p><strong>代码解释</strong></p>
<p>softmax_loss_naive(W, X, y, reg):</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">num_classes = W.shape[<span class="number">1</span>]</span><br><span class="line">num_train = X.shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(num_train):</span><br><span class="line">   scores = X[i].dot(W)</span><br><span class="line">   shift_scores = scores - max(scores)</span><br><span class="line">   loss_i = - shift_scores[y[i]] + np.log(sum(np.exp(shift_scores)))</span><br><span class="line">   loss += loss_i</span><br><span class="line">   <span class="keyword">for</span> j <span class="keyword">in</span> range(num_classes):</span><br><span class="line">       softmax_output = np.exp(shift_scores[j])/sum(np.exp(shift_scores))</span><br><span class="line">       <span class="keyword">if</span> j == y[i]:</span><br><span class="line">           dW[:,j] += (<span class="number">-1</span> + softmax_output) *X[i]</span><br><span class="line">       <span class="keyword">else</span>:</span><br><span class="line">           dW[:,j] += softmax_output *X[i]</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>shift_scores 就是上面指出的  Numeric stability。</p>
<p>loss_i 是上面损失函数第二个式子。</p>
<p>softmax_output：<br>链式法则<br>$$\frac{dloss} {dw} = \frac{dloss}{df_j}.\frac{df_j}{dw}$$<br>后面一项为 X[i]，主要计算前面。<br>$j = y_j$对分子求偏导:<br>$$\frac{\partial loss}{\partial f_j} = (-\log( {e^{f_{y_i}} \over \sum_je^{f_j} }))’={e^{f_{y_i}} \over \sum_je^{f_j} }-1$$</p>
<p>$j \neq y_j$对分母求偏导:<br>$$\frac{\partial loss}{\partial f_j} = (-\log( {e^{f_{y_i}} \over \sum_je^{f_j} }))’={e^{f_{y_i}} \over \sum_je^{f_j} }$$</p>
<p>softmax_loss_vectorized(W, X, y, reg):</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">scores = X.dot(W)</span><br><span class="line">shift_scores = scores - np.max(scores, axis = <span class="number">1</span>).reshape(<span class="number">-1</span>,<span class="number">1</span>)</span><br><span class="line">softmax_output = np.exp(shift_scores)/np.sum(np.exp(shift_scores), axis = <span class="number">1</span>).reshape(<span class="number">-1</span>,<span class="number">1</span>)</span><br><span class="line">loss = -np.sum(np.log(softmax_output[range(num_train), list(y)]))</span><br><span class="line">loss /= num_train</span><br><span class="line">loss +=  <span class="number">0.5</span>* reg * np.sum(W * W)</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>参考loss function前面一个式子。</p>
<h3 id="SVM-vs-Softmax"><a href="#SVM-vs-Softmax" class="headerlink" title="SVM vs. Softmax"></a>SVM vs. Softmax</h3><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="http://cs231n.github.io/assets/svmvssoftmax.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
<p>softmax分类器对于分数是永远不会满意的：正确分类总能得到更高的可能性，错误分类总能得到更低的可能性，损失值总是能够更小。<br>但是，SVM只要边界值被满足了就满意了。</p>
<p>eg.</p>
<p>SVM对于数字个体的细节是不关心的：如果分数是[10, -100, -100]或者[10, 9, 9]，对于SVM来说没设么不同，只要满足超过边界值等于1，那么损失值就等于0。</p>
<p>对于softmax分类器，情况则不同。对于[10, 9, 9]来说，计算出的损失值就远远高于[10, -100, -100]的。</p>
<p><a href="http://vision.stanford.edu/teaching/cs231n-demos/linear-classify/" target="_blank" rel="noopener">Interactive web demo</a></p>
<hr>
<h1 id="Unknown-words"><a href="#Unknown-words" class="headerlink" title="Unknown words"></a>Unknown words</h1><hr>
<p>simplicity  简单  n<br>seemingly   貌似  adv<br>distinct    清楚的 adj<br>quarter     四分之一<br>trivial    简单，不重要的 adj.<br>instance    实例<br>be oriented in<br>exhibit variation  表现出差异<br>extreme     极端的<br>rigid       刚性，僵硬的<br>occlude     挡住<br>a portion of        一部分<br>clutter     杂乱<br>blend into  融入</p>
<hr>
<ul>
<li>annotate    注释    vt.</li>
<li>catalog        登记成册    vt<br>interdisciplinary    跨学科    adj.<br>constellation        一群    n.<br>neuroscience        神经科学<br>overlap            重叠部分</li>
<li>concurrently        同时    adv.<br>encompassing        包含<br>seminar            研讨会<br>syllabus            教学大纲<br>tag    team        两人一组<br>take over       接管</li>
<li>agenda            议程<br>chill                寒冷</li>
<li>onset            开始<br>proactive            积极主动</li>
<li>go after            追逐<br>predators went after prey    捕食者 / 被捕食者<br>intelligent animal    智慧动物</li>
<li>manipulate        操纵<br>Renaissance period of time    文艺复兴期间<br>obscuration        昏暗<br>pinhole            小孔<br>in the mean time    同时<br>inspired             受到启发<br>electrode            电极<br>primary visual cortex    初级视觉皮层</li>
<li>by and large        大体上说</li>
<li>thesis            论文<br>geometric        几何<br>linear algebra            线性代数<br>pay tribute to    sb.    赞扬sb.</li>
<li>holistic            全面的    adj.</li>
<li>idealized            理想化的      adj.    </li>
<li>intuitive            直观的            adj.<br>intuition            直觉<br>deconstruct        解构</li>
<li>seminal            意义深远的   adj.</li>
<li>cylinder            圆柱</li>
<li>generalized         广义的     adj.</li>
<li>elastic            可伸缩的    adj.<br>razor            剃须刀</li>
<li>frankly            坦白地 adv.<br>audacious        大胆地</li>
<li>ambitious        雄心勃勃的</li>
<li>made some headway    有一些进展<br>gain momentum        见效<br>boosting            助推</li>
<li>There is a lot to admire this work. ?<br>near-real-time        近实时的</li>
<li>roll out            推出<br>occlusion            遮挡</li>
<li>intrinsic            本质的   adj.<br>diagnostic        诊断的</li>
<li>pyramid            金字塔</li>
<li>clue                线索    vt/n<br>highway            公路</li>
<li>compose            组成<br>histogram of gradient    梯度直方图</li>
<li>deformable         可变形的 adj.</li>
<li>all along            自始至终</li>
<li>bottleneck        瓶颈</li>
<li>benchmarking        基准学习</li>
<li>gigantic            巨大的<br>stringent            严格的</li>
<li>on par with        达到相当的水平</li>
<li>hover            （数值）徘徊在，原义为翱翔<br>deep dive            深入学习<br>have a deep dive into convolutional neural network<br>tremendous capacity    巨大的能力</li>
<li>academia            学术界</li>
<li>calory            卡路里<br>image captioning    给图像加解说</li>
<li>tweaking            调整</li>
<li>collaborator        合作者<br>deploy            部署</li>
<li>coarse            粗糙的<br>transistor            晶体管<br>orders magnitude     数量级<br>crunching         运算</li>
<li>capacity            容量</li>
<li>fancy            设想<br>pop up            突然出现,弹出</li>
<li>tackle            解决,处理</li>
<li>semantic            语义的<br>perceptional        知觉的<br>augmented reality    增强现实<br>intricacy            错综复杂的事物</li>
<li>exposure            暴露 n.</li>
<li>holy grail            圣杯</li>
<li>exemplify            举例说明  vt.</li>
<li>conscious            有意识的<br>respectable        可敬的<br>compatriot        同胞</li>
<li>by no means        决不<br>hallucinate        使产生幻觉<br>psychedelic        迷幻的</li>
<li>render            渲染,给予<br>extenuating        情有可原的</li>
<li>circumstance        环境</li>
<li>prerequisite        先决条件</li>
<li>calculus            微积分</li>
<li>derivative        导数<br>reintroduce        恢复</li>
<li>discard       丢弃</li>
<li>penalty       惩罚</li>
</ul>
<hr>

        </div>

        <blockquote class="post-copyright">
    <div class="content">
        
<span class="post-time">
    Last updated: <time datetime="2018-05-23T02:29:39.396Z" itemprop="dateUpdated">2018-05-23 10:29:39</time>
</span><br>


        
        <img src="http://7xsg2l.com1.z0.glb.clouddn.com/blog/imgxd.jpeg">
        
    </div>
    <footer>
        <a href="http://wenbo.fun">
            <img src="http://7xsg2l.com1.z0.glb.clouddn.com/blog/img/cc.jpeg" alt="Wen bo">
            Wen bo
        </a>
    </footer>
</blockquote>

        
<div class="page-reward">
    <a id="rewardBtn" href="javascript:;" class="page-reward-btn waves-effect waves-circle waves-light">赏</a>
</div>



        <div class="post-footer">
            
	<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/CNN/">CNN</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/笔记/">笔记</a></li></ul>


            
<div class="page-share-wrap">
    

<div class="page-share" id="pageShare">
    <ul class="reset share-icons">
      <li>
        <a class="weibo share-sns" target="_blank" href="http://service.weibo.com/share/share.php?url=http://wenbo.fun/2018/04/11/cs231n_m1_1/&title=《CS231n学习笔记 Module 1.1》 — E.I.&pic=http://7xsg2l.com1.z0.glb.clouddn.com/blog/img/cc.jpeg" data-title="微博">
          <i class="icon icon-weibo"></i>
        </a>
      </li>
      <li>
        <a class="weixin share-sns wxFab" href="javascript:;" data-title="微信">
          <i class="icon icon-weixin"></i>
        </a>
      </li>
      <li>
        <a class="qq share-sns" target="_blank" href="http://connect.qq.com/widget/shareqq/index.html?url=http://wenbo.fun/2018/04/11/cs231n_m1_1/&title=《CS231n学习笔记 Module 1.1》 — E.I.&source=Abstract
Assignment Git:https://github.com/CS231n-zju/CS231n
视频地址：https://www..." data-title=" QQ">
          <i class="icon icon-qq"></i>
        </a>
      </li>
      <li>
        <a class="facebook share-sns" target="_blank" href="https://www.facebook.com/sharer/sharer.php?u=http://wenbo.fun/2018/04/11/cs231n_m1_1/" data-title=" Facebook">
          <i class="icon icon-facebook"></i>
        </a>
      </li>
      <li>
        <a class="twitter share-sns" target="_blank" href="https://twitter.com/intent/tweet?text=《CS231n学习笔记 Module 1.1》 — E.I.&url=http://wenbo.fun/2018/04/11/cs231n_m1_1/&via=http://wenbo.fun" data-title=" Twitter">
          <i class="icon icon-twitter"></i>
        </a>
      </li>
      <li>
        <a class="google share-sns" target="_blank" href="https://plus.google.com/share?url=http://wenbo.fun/2018/04/11/cs231n_m1_1/" data-title=" Google+">
          <i class="icon icon-google-plus"></i>
        </a>
      </li>
    </ul>
 </div>



    <a href="javascript:;" id="shareFab" class="page-share-fab waves-effect waves-circle">
        <i class="icon icon-share-alt icon-lg"></i>
    </a>
</div>



        </div>
    </div>

    
<nav class="post-nav flex-row flex-justify-between">
  
    <div class="waves-block waves-effect prev">
      <a href="/2018/04/17/cs231n_m1_3/" id="post-prev" class="post-nav-link">
        <div class="tips"><i class="icon icon-angle-left icon-lg icon-pr"></i> Prev</div>
        <h4 class="title">CS231n学习笔记 Module 1.3</h4>
      </a>
    </div>
  

  
    <div class="waves-block waves-effect next">
      <a href="/2018/03/30/Mean-shift/" id="post-next" class="post-nav-link">
        <div class="tips">Next <i class="icon icon-angle-right icon-lg icon-pl"></i></div>
        <h4 class="title">Mean-shift clustering algorithm</h4>
      </a>
    </div>
  
</nav>



    











    <!-- Valine Comments -->
    <div class="comments vcomment" id="comments"></div>
    <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
    <script src="//unpkg.com/valine@latest/dist/Valine.min.js"></script>
    <!-- Valine Comments script -->
    <script>
        var GUEST_INFO = ['nick','mail','link'];
        var guest_info = 'nick,mail'.split(',').filter(function(item){
          return GUEST_INFO.indexOf(item) > -1
        });
        new Valine({
            el: '#comments',
            notify: 'false' == 'true',
            verify: 'false' == 'true',
            appId: "xVQIAhS8Iaa22qibuCeoAjj2-gzGzoHsz",
            appKey: "GEc59stbeS88ePxaVibVE1Db",
            avatar: "monsterid",
            placeholder: "Just go go",
            guest_info: guest_info.length == 0 ? GUEST_INFO : guest_info,
            pageSize: "10"
        })
    </script>
    <!-- Valine Comments end -->




</article>

<div id="reward" class="page-modal reward-lay">
    <a class="close" href="javascript:;"><i class="icon icon-close"></i></a>
    <h3 class="reward-title">
        <i class="icon icon-quote-left"></i>
        谢谢亲~
        <i class="icon icon-quote-right"></i>
    </h3>
    <div class="reward-content">
        
        <div class="reward-code">
            <img id="rewardCode" src="http://7xsg2l.com1.z0.glb.clouddn.com/blog/img/wechat.jpg" alt="打赏二维码">
        </div>
        
        <label class="reward-toggle">
            <input id="rewardToggle" type="checkbox" class="reward-toggle-check"
                data-wechat="http://7xsg2l.com1.z0.glb.clouddn.com/blog/img/wechat.jpg" data-alipay="http://7xsg2l.com1.z0.glb.clouddn.com/blog/img/alipay.jpg">
            <div class="reward-toggle-ctrol">
                <span class="reward-toggle-item wechat">微信</span>
                <span class="reward-toggle-label"></span>
                <span class="reward-toggle-item alipay">支付宝</span>
            </div>
        </label>
        
    </div>
</div>



</div>

        <footer class="footer">
    <div class="top">
        
<p>
    <span id="busuanzi_container_site_uv" style='display:none'>
        站点总访客数：<span id="busuanzi_value_site_uv"></span>
    </span>
    <span id="busuanzi_container_site_pv" style='display:none'>
        站点总访问量：<span id="busuanzi_value_site_pv"></span>
    </span>
</p>


        <p>
            
                <span><a href="/atom.xml" target="_blank" class="rss" title="rss"><i class="icon icon-lg icon-rss"></i></a></span>
            
            <span>This blog is licensed under a <a rel="license" href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.</span>
        </p>
    </div>
    <div class="bottom">
        <p><span>Wen bo &copy; 2017 - 2018</span>
            <span>
                
                Power by <a href="http://hexo.io/" target="_blank">Hexo</a> 
            </span>
        </p>
    </div>
</footer>

    </main>
    <div class="mask" id="mask"></div>
<a href="javascript:;" id="gotop" class="waves-effect waves-circle waves-light"><span class="icon icon-lg icon-chevron-up"></span></a>



<div class="global-share" id="globalShare">
    <ul class="reset share-icons">
      <li>
        <a class="weibo share-sns" target="_blank" href="http://service.weibo.com/share/share.php?url=http://wenbo.fun/2018/04/11/cs231n_m1_1/&title=《CS231n学习笔记 Module 1.1》 — E.I.&pic=http://7xsg2l.com1.z0.glb.clouddn.com/blog/img/cc.jpeg" data-title="微博">
          <i class="icon icon-weibo"></i>
        </a>
      </li>
      <li>
        <a class="weixin share-sns wxFab" href="javascript:;" data-title="微信">
          <i class="icon icon-weixin"></i>
        </a>
      </li>
      <li>
        <a class="qq share-sns" target="_blank" href="http://connect.qq.com/widget/shareqq/index.html?url=http://wenbo.fun/2018/04/11/cs231n_m1_1/&title=《CS231n学习笔记 Module 1.1》 — E.I.&source=Abstract
Assignment Git:https://github.com/CS231n-zju/CS231n
视频地址：https://www..." data-title=" QQ">
          <i class="icon icon-qq"></i>
        </a>
      </li>
      <li>
        <a class="facebook share-sns" target="_blank" href="https://www.facebook.com/sharer/sharer.php?u=http://wenbo.fun/2018/04/11/cs231n_m1_1/" data-title=" Facebook">
          <i class="icon icon-facebook"></i>
        </a>
      </li>
      <li>
        <a class="twitter share-sns" target="_blank" href="https://twitter.com/intent/tweet?text=《CS231n学习笔记 Module 1.1》 — E.I.&url=http://wenbo.fun/2018/04/11/cs231n_m1_1/&via=http://wenbo.fun" data-title=" Twitter">
          <i class="icon icon-twitter"></i>
        </a>
      </li>
      <li>
        <a class="google share-sns" target="_blank" href="https://plus.google.com/share?url=http://wenbo.fun/2018/04/11/cs231n_m1_1/" data-title=" Google+">
          <i class="icon icon-google-plus"></i>
        </a>
      </li>
    </ul>
 </div>


<div class="page-modal wx-share" id="wxShare">
    <a class="close" href="javascript:;"><i class="icon icon-close"></i></a>
    <p>扫一扫，分享到微信</p>
    <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAK4AAACuCAAAAACKZ2kyAAABvUlEQVR42u3aS5LCMAwFQO5/6cyWTcKTZLtgqr2iwDGdjUofv17xut7W3ffvv1436/m0ZQsXF3fMvR5XlXu3J/mcnIaLi3uSexcxnvckgWlyPi4u7q9w8/3PO3Fxcf8TNw9tzzhcXNzv5ybFTzVg9YqrZbUaLi7ugJt3Kfd93tLfxcXFbXGv4koanZPG6Id/x8XFPcLNA0r1ZfIzy8NdXFzcI9yklZkXOdWEKQ+OuLi438PNRyCTX5vNEVxc3CPceemSP5UkUlGIxMXFXcq9ezg/rpoSVV/jtouDi4u7jbt7WlG9bFEet+Di4m7jPoetvCiqXtJqtl9xcXE3c6vQXkKTpzIfAh8uLu4R7uQyVrlQKQa16sgWFxd3B7cXhiZPja5o4OLibuY241zxclV1GBPVari4uEe4o9nseNwS/S8uLu5B7qQ9uiDDyvfg4uJu5vZGqtUT8pD3msRIXFzcRdx8VUcmyUWKJHlqvgwuLu6YO7l6le/pDWg/FD+4uLibufmQtVcCLUtlcHFxf5CbFzbV8S0uLu43cyetkAWxCxcX9yB3x1i0GapW1Wq4uLgDbq/imBQ/VSguLu5B7h+KX7loGgss/gAAAABJRU5ErkJggg==" alt="微信分享二维码">
</div>




    <script src="//cdn.bootcss.com/node-waves/0.7.4/waves.min.js"></script>
<script>
var BLOG = { ROOT: '/', SHARE: true, REWARD: true };


</script>

<script src="/js/main.min.js?v=1.7.1"></script>


<div class="search-panel" id="search-panel">
    <ul class="search-result" id="search-result"></ul>
</div>
<template id="search-tpl">
<li class="item">
    <a href="{path}" class="waves-block waves-effect">
        <div class="title ellipsis" title="{title}">{title}</div>
        <div class="flex-row flex-middle">
            <div class="tags ellipsis">
                {tags}
            </div>
            <time class="flex-col time">{date}</time>
        </div>
    </a>
</li>
</template>

<script src="/js/search.min.js?v=1.7.1" async></script>



<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
});
</script>

<script async src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML" async></script>




<script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>



<script>
(function() {
    var OriginTitile = document.title, titleTime;
    document.addEventListener('visibilitychange', function() {
        if (document.hidden) {
            document.title = '去哪里了！';
            clearTimeout(titleTime);
        } else {
            document.title = '(つェ⊂)咦!又好了!';
            titleTime = setTimeout(function() {
                document.title = OriginTitile;
            },2000);
        }
    });
})();
</script>



    
<div id="hexo-helper-live2d">
  <canvas id="live2dcanvas" width="225" height="450"></canvas>
</div>
<style>
  #live2dcanvas{
    position: fixed;
    width: 150px;
    height: 300px;
    opacity:1;
    right: 50px;
    z-index: 999;
    pointer-events: none;
    bottom: -60px;
  }
</style>
<script type="text/javascript" src="/live2d/device.min.js"></script>
<script type="text/javascript">
const loadScript = function loadScript(c,b){var a=document.createElement("script");a.type="text/javascript";"undefined"!=typeof b&&(a.readyState?a.onreadystatechange=function(){if("loaded"==a.readyState||"complete"==a.readyState)a.onreadystatechange=null,b()}:a.onload=function(){b()});a.src=c;document.body.appendChild(a)};
(function(){
  if((typeof(device) != 'undefined') && (device.mobile())){
    document.getElementById("live2dcanvas").style.width = '75px';
    document.getElementById("live2dcanvas").style.height = '150px';
  }else
    if (typeof(device) === 'undefined') console.error('Cannot find current-device script.');
  loadScript("/live2d/script.js", function(){loadlive2d("live2dcanvas", "/live2d/assets/unitychan.model.json", 0.5);});
})();
</script>

</body>
</html>
